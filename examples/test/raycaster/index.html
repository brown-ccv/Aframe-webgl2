<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Raycaster</title>
    <meta name="description" content="Raycaster - A-Frame">
    <script src="../../../dist/aframe-master.js"></script>
	<script src="../../../dist/gunzip.min.js"></script>
	<script>

var NRRDLoader = function (manager) {
  this.manager = (manager !== undefined) ? manager : THREE.DefaultLoadingManager;
};

NRRDLoader.prototype = {

  constructor: NRRDLoader,

  load: function (url, onLoad, onProgress, onError) {
    var scope = this;

    var loader = new THREE.FileLoader(scope.manager);
    loader.setPath(scope.path);
    loader.setResponseType('arraybuffer');
    loader.load(url, function (data) {
      onLoad(scope.parse(data));
    }, onProgress, onError);
  },

  setPath: function (value) {
    this.path = value;
    return this;
  },

  parse: function (data) {
    // this parser is largely inspired from the XTK NRRD parser : https://github.com/xtk/X

    var _data = data;

    var _dataPointer = 0;

    var _nativeLittleEndian = new Int8Array(new Int16Array([ 1 ]).buffer)[ 0 ] > 0;

    var _littleEndian = true;

    var headerObject = {};

    function scan (type, chunks) {
      if (chunks === undefined || chunks === null) {
        chunks = 1;
      }

      var _chunkSize = 1;
      var _array_type = Uint8Array;

      switch (type) {

        // 1 byte data types
        case 'uchar':
          break;
        case 'schar':
          _array_type = Int8Array;
          break;
         // 2 byte data types
        case 'ushort':
          _array_type = Uint16Array;
          _chunkSize = 2;
          break;
        case 'sshort':
          _array_type = Int16Array;
          _chunkSize = 2;
          break;
        // 4 byte data types
        case 'uint':
          _array_type = Uint32Array;
          _chunkSize = 4;
          break;
        case 'sint':
          _array_type = Int32Array;
          _chunkSize = 4;
          break;
        case 'float':
          _array_type = Float32Array;
          _chunkSize = 4;
          break;
        case 'complex':
          _array_type = Float64Array;
          _chunkSize = 8;
          break;
        case 'double':
          _array_type = Float64Array;
          _chunkSize = 8;
          break;

      }

       // increase the data pointer in-place
      var _bytes = new _array_type(_data.slice(_dataPointer, _dataPointer += chunks * _chunkSize));

       // if required, flip the endianness of the bytes
      if (_nativeLittleEndian != _littleEndian) {
       // we need to flip here since the format doesn't match the native endianness
        _bytes = flipEndianness(_bytes, _chunkSize);
      }

      if (chunks == 1) {
        // if only one chunk was requested, just return one value
        return _bytes[ 0 ];
      }

        // return the byte array
      return _bytes;
    }

       // Flips typed array endianness in-place. Based on https://github.com/kig/DataStream.js/blob/master/DataStream.js.

    function flipEndianness (array, chunkSize) {
      var u8 = new Uint8Array(array.buffer, array.byteOffset, array.byteLength);
      for (var i = 0; i < array.byteLength; i += chunkSize) {
        for (var j = i + chunkSize - 1, k = i; j > k; j--, k++) {
          var tmp = u8[ k ];
          u8[ k ] = u8[ j ];
          u8[ j ] = tmp;
        }
      }

      return array;
    }

      // parse the header
    function parseHeader (header) {
      var data, field, fn, i, l, lines, m, _i, _len;
      lines = header.split(/\r?\n/);
      for (_i = 0, _len = lines.length; _i < _len; _i++) {
        l = lines[ _i ];
        if (l.match(/NRRD\d+/)) {
          headerObject.isNrrd = true;
        } else if (l.match(/^#/)) {
        } else if (m = l.match(/(.*):(.*)/)) {
          field = m[ 1 ].trim();
          data = m[ 2 ].trim();
          fn = NRRDLoader.prototype.fieldFunctions[ field ];
          if (fn) {
            fn.call(headerObject, data);
          } else {
            headerObject[ field ] = data;
          }
        }
      }
      if (!headerObject.isNrrd) {
        throw new Error('Not an NRRD file');
      }
      if (headerObject.encoding === 'bz2' || headerObject.encoding === 'bzip2') {
        throw new Error('Bzip is not supported');
      }
      if (!headerObject.vectors) {
        // if no space direction is set, let's use the identity
        headerObject.vectors = [ new THREE.Vector3(1, 0, 0), new THREE.Vector3(0, 1, 0), new THREE.Vector3(0, 0, 1) ];
        // apply spacing if defined
        if (headerObject.spacings) {
          for (i = 0; i <= 2; i++) {
            if (!isNaN(headerObject.spacings[ i ])) {
              headerObject.vectors[ i ].multiplyScalar(headerObject.spacings[ i ]);
            }
          }
        }
      }
    }

     // parse the data when registred as one of this type : 'text', 'ascii', 'txt'
    function parseDataAsText (data, start, end) {
      var number = '';
      start = start || 0;
      end = end || data.length;
      var value;
      // length of the result is the product of the sizes
      var lengthOfTheResult = headerObject.sizes.reduce(function (previous, current) {
        return previous * current;
      }, 1);

      var base = 10;
      if (headerObject.encoding === 'hex') {
        base = 16;
      }

      var result = new headerObject.__array(lengthOfTheResult);
      var resultIndex = 0;
      var parsingFunction = parseInt;
      if (headerObject.__array === Float32Array || headerObject.__array === Float64Array) {
        parsingFunction = parseFloat;
      }
      for (var i = start; i < end; i++) {
        value = data[ i ];
         // if value is not a space
        if ((value < 9 || value > 13) && value !== 32) {
          number += String.fromCharCode(value);
        } else {
          if (number !== '') {
            result[ resultIndex ] = parsingFunction(number, base);
            resultIndex++;
          }
          number = '';
        }
      }
      if (number !== '') {
        result[ resultIndex ] = parsingFunction(number, base);
        resultIndex++;
      }
      return result;
    }

    var _bytes = scan('uchar', data.byteLength);
    var _length = _bytes.length;
    var _header = null;
    var _data_start = 0;
    var i;
    for (i = 1; i < _length; i++) {
      if (_bytes[ i - 1 ] == 10 && _bytes[ i ] == 10) {
        // we found two line breaks in a row
        // now we know what the header is
        _header = this.parseChars(_bytes, 0, i - 2);
         // this is were the data starts
        _data_start = i + 1;
        break;
      }
    }
     // parse the header
    parseHeader(_header);

    var _data = _bytes.subarray(_data_start); // the data without header
    if (headerObject.encoding === 'gzip' || headerObject.encoding === 'gz') {
      // we need to decompress the datastream
      // here we start the unzipping and get a typed Uint8Array back
      var inflate = new zlib.Gunzip(new Uint8Array(_data)); // eslint-disable-line no-undef
      _data = inflate.decompress();
    } else if (headerObject.encoding === 'ascii' || headerObject.encoding === 'text' || headerObject.encoding === 'txt' || headerObject.encoding === 'hex') {
      _data = parseDataAsText(_data);
    } else if (headerObject.encoding === 'raw') {
      // we need to copy the array to create a new array buffer, else we retrieve the original arraybuffer with the header
      var _copy = new Uint8Array(_data.length);

      for (var i = 0; i < _data.length; i++) {
        _copy[ i ] = _data[ i ];
      }

      _data = _copy;
    }
      // .. let's use the underlying array buffer
    _data = _data.buffer;

    var volume = new THREE.Volume();
    volume.header = headerObject;
      //
      // parse the (unzipped) data to a datastream of the correct type
      //
    volume.data = new headerObject.__array(_data);
      // get the min and max intensities
    var min_max = volume.computeMinMax();
    var min = min_max[ 0 ];
    var max = min_max[ 1 ];
      // attach the scalar range to the volume
    volume.windowLow = min;
    volume.windowHigh = max;

      // get the image dimensions
    volume.dimensions = [ headerObject.sizes[ 0 ], headerObject.sizes[ 1 ], headerObject.sizes[ 2 ] ];
    volume.xLength = volume.dimensions[ 0 ];
    volume.yLength = volume.dimensions[ 1 ];
    volume.zLength = volume.dimensions[ 2 ];
      // spacing
    var spacingX = (new THREE.Vector3(headerObject.vectors[ 0 ][ 0 ], headerObject.vectors[ 0 ][ 1 ], headerObject.vectors[ 0 ][ 2 ])).length();
    var spacingY = (new THREE.Vector3(headerObject.vectors[ 1 ][ 0 ], headerObject.vectors[ 1 ][ 1 ], headerObject.vectors[ 1 ][ 2 ])).length();
    var spacingZ = (new THREE.Vector3(headerObject.vectors[ 2 ][ 0 ], headerObject.vectors[ 2 ][ 1 ], headerObject.vectors[ 2 ][ 2 ])).length();
    volume.spacing = [ spacingX, spacingY, spacingZ ];

      // Create IJKtoRAS matrix
    volume.matrix = new THREE.Matrix4();

    var _spaceX = 1;
    var _spaceY = 1;
    var _spaceZ = 1;

    if (headerObject.space == 'left-posterior-superior') {
      _spaceX = -1;
      _spaceY = -1;
    } else if (headerObject.space === 'left-anterior-superior') {
      _spaceX = -1;
    }

    if (!headerObject.vectors) {
      volume.matrix.set(_spaceX, 0, 0, 0,
                         0, _spaceY, 0, 0,
                         0, 0, _spaceZ, 0,
                         0, 0, 0, 1);
    } else {
      var v = headerObject.vectors;

      volume.matrix.set(_spaceX * v[ 0 ][ 0 ], _spaceX * v[ 1 ][ 0 ], _spaceX * v[ 2 ][ 0 ], 0,
                        _spaceY * v[ 0 ][ 1 ], _spaceY * v[ 1 ][ 1 ], _spaceY * v[ 2 ][ 1 ], 0,
                        _spaceZ * v[ 0 ][ 2 ], _spaceZ * v[ 1 ][ 2 ], _spaceZ * v[ 2 ][ 2 ], 0,
                        0, 0, 0, 1);
    }

    volume.inverseMatrix = new THREE.Matrix4();
    volume.inverseMatrix.getInverse(volume.matrix);
    volume.RASDimensions = (new THREE.Vector3(volume.xLength, volume.yLength, volume.zLength)).applyMatrix4(volume.matrix).round().toArray().map(Math.abs);

      // .. and set the default threshold
      // only if the threshold was not already set
    if (volume.lowerThreshold === -Infinity) {
      volume.lowerThreshold = min;
    }
    if (volume.upperThreshold === Infinity) {
      volume.upperThreshold = max;
    }

    return volume;
  },

  parseChars: function (array, start, end) {
    // without borders, use the whole array
    if (start === undefined) {
      start = 0;
    }
    if (end === undefined) {
      end = array.length;
    }

    var output = '';
     // create and append the chars
    var i = 0;
    for (i = start; i < end; ++i) {
      output += String.fromCharCode(array[ i ]);
    }

    return output;
  },

  fieldFunctions: {

    type: function (data) {
      switch (data) {

        case 'uchar':
        case 'unsigned char':
        case 'uint8':
        case 'uint8_t':
          this.__array = Uint8Array;
          break;
        case 'signed char':
        case 'int8':
        case 'int8_t':
          this.__array = Int8Array;
          break;
        case 'short':
        case 'short int':
        case 'signed short':
        case 'signed short int':
        case 'int16':
        case 'int16_t':
          this.__array = Int16Array;
          break;
        case 'ushort':
        case 'unsigned short':
        case 'unsigned short int':
        case 'uint16':
        case 'uint16_t':
          this.__array = Uint16Array;
          break;
        case 'int':
        case 'signed int':
        case 'int32':
        case 'int32_t':
          this.__array = Int32Array;
          break;
        case 'uint':
        case 'unsigned int':
        case 'uint32':
        case 'uint32_t':
          this.__array = Uint32Array;
          break;
        case 'float':
          this.__array = Float32Array;
          break;
        case 'double':
          this.__array = Float64Array;
          break;
        default:
          throw new Error('Unsupported NRRD data type: ' + data);

      }

      return this.type = data;
    },

    endian: function (data) {
      return this.endian = data;
    },

    encoding: function (data) {
      return this.encoding = data;
    },

    dimension: function (data) {
      return this.dim = parseInt(data, 10);
    },

    sizes: function (data) {
      var i;
      return this.sizes = (function () {
        var _i, _len, _ref, _results;
        _ref = data.split(/\s+/);
        _results = [];
        for (_i = 0, _len = _ref.length; _i < _len; _i++) {
          i = _ref[ _i ];
          _results.push(parseInt(i, 10));
        }
        return _results;
      })();
    },

    space: function (data) {
      return this.space = data;
    },

    'space origin': function (data) {
      return this.space_origin = data.split('(')[ 1 ].split(')')[ 0 ].split(',');
    },

    'space directions': function (data) {
      var f, parts, v;
      parts = data.match(/\(.*?\)/g);
      return this.vectors = (function () {
        var _i, _len, _results;
        _results = [];
        for (_i = 0, _len = parts.length; _i < _len; _i++) {
          v = parts[ _i ];
          _results.push((function () {
            var _j, _len2, _ref, _results2;
            _ref = v.slice(1, -1).split(/,/);
            _results2 = [];
            for (_j = 0, _len2 = _ref.length; _j < _len2; _j++) {
              f = _ref[ _j ];
              _results2.push(parseFloat(f));
            }
            return _results2;
          })());
        }
        return _results;
      })();
    },

    spacings: function (data) {
      var f, parts;
      parts = data.split(/\s+/);
      return this.spacings = (function () {
        var _len = 0;
        var _results = [];

        for (var _i = 0, _len = parts.length; _i < _len; _i++) {
          f = parts[ _i ];
          _results.push(parseFloat(f));
        }
        return _results;
      })();
    }
  }

};	
	
AFRAME.registerComponent('mythreejsthing', {
  schema: {
    color: {
      default: '#000'
    },
  },

  update: function() {
    var material = new THREE.MeshBasicMaterial({
      color: this.data.color,
      wireframe: true
    });

    var geometry = new THREE.BoxGeometry(1, 1, 1);

    this.el.setObject3D('mesh', new THREE.Mesh(geometry, material));
  },

  remove: function() {
    this.el.removeObject3D('mesh');
  }
});



THREE.ShaderLib[ 'libvolumeRenderShader' ] = {
  uniforms: {
				"u_size": { value: new THREE.Vector3( 1, 1, 1 ) },
				"u_renderstyle": { value: 0 },
				"u_renderthreshold": { value: 0.5 },
				"u_clim": { value: new THREE.Vector2( 1, 1 ) },
				"u_data": { value: null },
				"u_cmdata": { value: null }
		},
		vertexShader: [
				'varying vec4 v_nearpos;',
				'varying vec4 v_farpos;',
				'varying vec3 v_position;',

				'mat4 inversemat(mat4 m) {',
						// Taken from https://github.com/stackgl/glsl-inverse/blob/master/index.glsl
						// This function is licenced by the MIT license to Mikola Lysenko
						'float',
						'a00 = m[0][0], a01 = m[0][1], a02 = m[0][2], a03 = m[0][3],',
						'a10 = m[1][0], a11 = m[1][1], a12 = m[1][2], a13 = m[1][3],',
						'a20 = m[2][0], a21 = m[2][1], a22 = m[2][2], a23 = m[2][3],',
						'a30 = m[3][0], a31 = m[3][1], a32 = m[3][2], a33 = m[3][3],',

						'b00 = a00 * a11 - a01 * a10,',
						'b01 = a00 * a12 - a02 * a10,',
						'b02 = a00 * a13 - a03 * a10,',
						'b03 = a01 * a12 - a02 * a11,',
						'b04 = a01 * a13 - a03 * a11,',
						'b05 = a02 * a13 - a03 * a12,',
						'b06 = a20 * a31 - a21 * a30,',
						'b07 = a20 * a32 - a22 * a30,',
						'b08 = a20 * a33 - a23 * a30,',
						'b09 = a21 * a32 - a22 * a31,',
						'b10 = a21 * a33 - a23 * a31,',
						'b11 = a22 * a33 - a23 * a32,',

						'det = b00 * b11 - b01 * b10 + b02 * b09 + b03 * b08 - b04 * b07 + b05 * b06;',

				'return mat4(',
						'a11 * b11 - a12 * b10 + a13 * b09,',
						'a02 * b10 - a01 * b11 - a03 * b09,',
						'a31 * b05 - a32 * b04 + a33 * b03,',
						'a22 * b04 - a21 * b05 - a23 * b03,',
						'a12 * b08 - a10 * b11 - a13 * b07,',
						'a00 * b11 - a02 * b08 + a03 * b07,',
						'a32 * b02 - a30 * b05 - a33 * b01,',
						'a20 * b05 - a22 * b02 + a23 * b01,',
						'a10 * b10 - a11 * b08 + a13 * b06,',
						'a01 * b08 - a00 * b10 - a03 * b06,',
						'a30 * b04 - a31 * b02 + a33 * b00,',
						'a21 * b02 - a20 * b04 - a23 * b00,',
						'a11 * b07 - a10 * b09 - a12 * b06,',
						'a00 * b09 - a01 * b07 + a02 * b06,',
						'a31 * b01 - a30 * b03 - a32 * b00,',
						'a20 * b03 - a21 * b01 + a22 * b00) / det;',
				'}',


				'void main() {',
						// Prepare transforms to map to "camera view". See also:
						// https://threejs.org/docs/#api/renderers/webgl/WebGLProgram
						'mat4 viewtransformf = viewMatrix;',
						'mat4 viewtransformi = inversemat(viewMatrix);',

						// Project local vertex coordinate to camera position. Then do a step
						// backward (in cam coords) to the near clipping plane, and project back. Do
						// the same for the far clipping plane. This gives us all the information we
						// need to calculate the ray and truncate it to the viewing cone.
						'vec4 position4 = vec4(position, 1.0);',
						'vec4 pos_in_cam = viewtransformf * position4;',

						// Intersection of ray and near clipping plane (z = -1 in clip coords)
						'pos_in_cam.z = -pos_in_cam.w;',
						'v_nearpos = viewtransformi * pos_in_cam;',

						// Intersection of ray and far clipping plane (z = +1 in clip coords)
						'pos_in_cam.z = pos_in_cam.w;',
						'v_farpos = viewtransformi * pos_in_cam;',

						// Set varyings and output pos
						'v_position = position;',
						'gl_Position = projectionMatrix * viewMatrix * modelMatrix * position4;',
				'}',
		].join( '\n' ),
	fragmentShader: [
				'precision highp float;',
				'precision mediump sampler3D;',

				'uniform vec3 u_size;',
				'uniform int u_renderstyle;',
				'uniform float u_renderthreshold;',
				'uniform vec2 u_clim;',

				'uniform sampler3D u_data;',
				'uniform sampler2D u_cmdata;',

				'varying vec3 v_position;',
				'varying vec4 v_nearpos;',
				'varying vec4 v_farpos;',

				// The maximum distance through our rendering volume is sqrt(3).
				'const int MAX_STEPS = 887;	// 887 for 512^3, 1774 for 1024^3',
				'const int REFINEMENT_STEPS = 4;',
				'const float relative_step_size = 1.0;',
				'const vec4 ambient_color = vec4(0.2, 0.4, 0.2, 1.0);',
				'const vec4 diffuse_color = vec4(0.8, 0.2, 0.2, 1.0);',
				'const vec4 specular_color = vec4(1.0, 1.0, 1.0, 1.0);',
				'const float shininess = 40.0;',

				'void cast_mip(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray);',
				'void cast_iso(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray);',

				'float sample1(vec3 texcoords);',
				'vec4 apply_colormap(float val);',
				'vec4 add_lighting(float val, vec3 loc, vec3 step, vec3 view_ray);',


				'void main() {',
						// Normalize clipping plane info
						'vec3 farpos = v_farpos.xyz / v_farpos.w;',
						'vec3 nearpos = v_nearpos.xyz / v_nearpos.w;',

						// Calculate unit vector pointing in the view direction through this fragment.
						'vec3 view_ray = normalize(nearpos.xyz - farpos.xyz);',

						// Compute the (negative) distance to the front surface or near clipping plane.
						// v_position is the back face of the cuboid, so the initial distance calculated in the dot
						// product below is the distance from near clip plane to the back of the cuboid
						'float distance = dot(nearpos - v_position, view_ray);',
						'distance = max(distance, min((-0.5 - v_position.x) / view_ray.x,',
																				'(u_size.x - 0.5 - v_position.x) / view_ray.x));',
						'distance = max(distance, min((-0.5 - v_position.y) / view_ray.y,',
																				'(u_size.y - 0.5 - v_position.y) / view_ray.y));',
						'distance = max(distance, min((-0.5 - v_position.z) / view_ray.z,',
																				'(u_size.z - 0.5 - v_position.z) / view_ray.z));',

																				// Now we have the starting position on the front surface
						'vec3 front = v_position + view_ray * distance;',

						// Decide how many steps to take
						'int nsteps = int(-distance / relative_step_size + 0.5);',
						'if ( nsteps < 1 )',
								'discard;',

						// Get starting location and step vector in texture coordinates
						'vec3 step = ((v_position - front) / u_size) / float(nsteps);',
						'vec3 start_loc = front / u_size;',

						// For testing: show the number of steps. This helps to establish
						// whether the rays are correctly oriented
						//'gl_FragColor = vec4(0.0, float(nsteps) / 1.0 / u_size.x, 1.0, 1.0);',
						//'return;',

						'if (u_renderstyle == 0)',
								'cast_mip(start_loc, step, nsteps, view_ray);',
						'else if (u_renderstyle == 1)',
								'cast_iso(start_loc, step, nsteps, view_ray);',

						'if (gl_FragColor.a < 0.05)',
								'discard;',
				'}',


				'float sample1(vec3 texcoords) {',
						'/* Sample float value from a 3D texture. Assumes intensity data. */',
						'return texture(u_data, texcoords.xyz).r;',
				'}',


				'vec4 apply_colormap(float val) {',
						'val = (val - u_clim[0]) / (u_clim[1] - u_clim[0]);',
						'return texture2D(u_cmdata, vec2(val, 0.5));',
				'}',


				'void cast_mip(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray) {',

						'float max_val = -1e6;',
						'int max_i = 100;',
						'vec3 loc = start_loc;',

						// Enter the raycasting loop. In WebGL 1 the loop index cannot be compared with
						// non-constant expression. So we use a hard-coded max, and an additional condition
						// inside the loop.
						'for (int iter=0; iter<MAX_STEPS; iter++) {',
								'if (iter >= nsteps)',
										'break;',
								// Sample from the 3D texture
								'float val = sample1(loc);',
								// Apply MIP operation
								'if (val > max_val) {',
										'max_val = val;',
										'max_i = iter;',
								'}',
								// Advance location deeper into the volume
								'loc += step;',
						'}',

						// Refine location, gives crispier images
						'vec3 iloc = start_loc + step * (float(max_i) - 0.5);',
						'vec3 istep = step / float(REFINEMENT_STEPS);',
						'for (int i=0; i<REFINEMENT_STEPS; i++) {',
								'max_val = max(max_val, sample1(iloc));',
								'iloc += istep;',
						'}',

						// Resolve final color
						'gl_FragColor = apply_colormap(max_val);',
				'}',


				'void cast_iso(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray) {',

						'gl_FragColor = vec4(0.0);	// init transparent',
						'vec4 color3 = vec4(0.0);	// final color',
						'vec3 dstep = 1.5 / u_size;	// step to sample derivative',
						'vec3 loc = start_loc;',

						'float low_threshold = u_renderthreshold - 0.02 * (u_clim[1] - u_clim[0]);',

						// Enter the raycasting loop. In WebGL 1 the loop index cannot be compared with
						// non-constant expression. So we use a hard-coded max, and an additional condition
						// inside the loop.
						'for (int iter=0; iter<MAX_STEPS; iter++) {',
								'if (iter >= nsteps)',
										'break;',

										// Sample from the 3D texture
								'float val = sample1(loc);',

								'if (val > low_threshold) {',
								// Take the last interval in smaller steps
										'vec3 iloc = loc - 0.5 * step;',
										'vec3 istep = step / float(REFINEMENT_STEPS);',
										'for (int i=0; i<REFINEMENT_STEPS; i++) {',
												'val = sample1(iloc);',
												'if (val > u_renderthreshold) {',
														'gl_FragColor = add_lighting(val, iloc, dstep, view_ray);',
														'return;',
												'}',
												'iloc += istep;',
										'}',
								'}',

								// Advance location deeper into the volume
								'loc += step;',
						'}',
				'}',


				'vec4 add_lighting(float val, vec3 loc, vec3 step, vec3 view_ray)',
				'{',
						// Calculate color by incorporating lighting

						// View direction
						'vec3 V = normalize(view_ray);',

						// calculate normal vector from gradient
						'vec3 N;',
						'float val1, val2;',
						'val1 = sample1(loc + vec3(-step[0], 0.0, 0.0));',
						'val2 = sample1(loc + vec3(+step[0], 0.0, 0.0));',
						'N[0] = val1 - val2;',
						'val = max(max(val1, val2), val);',
						'val1 = sample1(loc + vec3(0.0, -step[1], 0.0));',
						'val2 = sample1(loc + vec3(0.0, +step[1], 0.0));',
						'N[1] = val1 - val2;',
						'val = max(max(val1, val2), val);',
						'val1 = sample1(loc + vec3(0.0, 0.0, -step[2]));',
						'val2 = sample1(loc + vec3(0.0, 0.0, +step[2]));',
						'N[2] = val1 - val2;',
						'val = max(max(val1, val2), val);',

						'float gm = length(N); // gradient magnitude',
						'N = normalize(N);',

						// Flip normal so it points towards viewer
						'float Nselect = float(dot(N, V) > 0.0);',
						'N = (2.0 * Nselect - 1.0) * N;	// ==	Nselect * N - (1.0-Nselect)*N;',

						// Init colors
						'vec4 ambient_color = vec4(0.0, 0.0, 0.0, 0.0);',
						'vec4 diffuse_color = vec4(0.0, 0.0, 0.0, 0.0);',
						'vec4 specular_color = vec4(0.0, 0.0, 0.0, 0.0);',

						// note: could allow multiple lights
						'for (int i=0; i<1; i++)',
						'{',
								 // Get light direction (make sure to prevent zero devision)
								'vec3 L = normalize(view_ray);	//lightDirs[i];',
								'float lightEnabled = float( length(L) > 0.0 );',
								'L = normalize(L + (1.0 - lightEnabled));',

								// Calculate lighting properties
								'float lambertTerm = clamp(dot(N, L), 0.0, 1.0);',
								'vec3 H = normalize(L+V); // Halfway vector',
								'float specularTerm = pow(max(dot(H, N), 0.0), shininess);',

								// Calculate mask
								'float mask1 = lightEnabled;',

								// Calculate colors
								'ambient_color +=	mask1 * ambient_color;	// * gl_LightSource[i].ambient;',
								'diffuse_color +=	mask1 * lambertTerm;',
								'specular_color += mask1 * specularTerm * specular_color;',
						'}',

						// Calculate final color by componing different components
						'vec4 final_color;',
						'vec4 color = apply_colormap(val);',
						'final_color = color * (ambient_color + diffuse_color) + specular_color;',
						'final_color.a = color.a;',
						'return final_color;',
				'}',
	].join( '\n' )

};


AFRAME.registerShader('volumeRenderShader', {
    uniforms: {
				"u_size": { value: new THREE.Vector3( 1, 1, 1 ) },
				"u_renderstyle": { value: 0 },
				"u_renderthreshold": { value: 0.5 },
				"u_clim": { value: new THREE.Vector2( 1, 1 ) },
				"u_data": { value: null },
				"u_cmdata": { value: null }
		},
		vertexShader: [
				'varying vec4 v_nearpos;',
				'varying vec4 v_farpos;',
				'varying vec3 v_position;',

				'mat4 inversemat(mat4 m) {',
						// Taken from https://github.com/stackgl/glsl-inverse/blob/master/index.glsl
						// This function is licenced by the MIT license to Mikola Lysenko
						'float',
						'a00 = m[0][0], a01 = m[0][1], a02 = m[0][2], a03 = m[0][3],',
						'a10 = m[1][0], a11 = m[1][1], a12 = m[1][2], a13 = m[1][3],',
						'a20 = m[2][0], a21 = m[2][1], a22 = m[2][2], a23 = m[2][3],',
						'a30 = m[3][0], a31 = m[3][1], a32 = m[3][2], a33 = m[3][3],',

						'b00 = a00 * a11 - a01 * a10,',
						'b01 = a00 * a12 - a02 * a10,',
						'b02 = a00 * a13 - a03 * a10,',
						'b03 = a01 * a12 - a02 * a11,',
						'b04 = a01 * a13 - a03 * a11,',
						'b05 = a02 * a13 - a03 * a12,',
						'b06 = a20 * a31 - a21 * a30,',
						'b07 = a20 * a32 - a22 * a30,',
						'b08 = a20 * a33 - a23 * a30,',
						'b09 = a21 * a32 - a22 * a31,',
						'b10 = a21 * a33 - a23 * a31,',
						'b11 = a22 * a33 - a23 * a32,',

						'det = b00 * b11 - b01 * b10 + b02 * b09 + b03 * b08 - b04 * b07 + b05 * b06;',

				'return mat4(',
						'a11 * b11 - a12 * b10 + a13 * b09,',
						'a02 * b10 - a01 * b11 - a03 * b09,',
						'a31 * b05 - a32 * b04 + a33 * b03,',
						'a22 * b04 - a21 * b05 - a23 * b03,',
						'a12 * b08 - a10 * b11 - a13 * b07,',
						'a00 * b11 - a02 * b08 + a03 * b07,',
						'a32 * b02 - a30 * b05 - a33 * b01,',
						'a20 * b05 - a22 * b02 + a23 * b01,',
						'a10 * b10 - a11 * b08 + a13 * b06,',
						'a01 * b08 - a00 * b10 - a03 * b06,',
						'a30 * b04 - a31 * b02 + a33 * b00,',
						'a21 * b02 - a20 * b04 - a23 * b00,',
						'a11 * b07 - a10 * b09 - a12 * b06,',
						'a00 * b09 - a01 * b07 + a02 * b06,',
						'a31 * b01 - a30 * b03 - a32 * b00,',
						'a20 * b03 - a21 * b01 + a22 * b00) / det;',
				'}',


				'void main() {',
						// Prepare transforms to map to "camera view". See also:
						// https://threejs.org/docs/#api/renderers/webgl/WebGLProgram
						'mat4 viewtransformf = viewMatrix;',
						'mat4 viewtransformi = inversemat(viewMatrix);',

						// Project local vertex coordinate to camera position. Then do a step
						// backward (in cam coords) to the near clipping plane, and project back. Do
						// the same for the far clipping plane. This gives us all the information we
						// need to calculate the ray and truncate it to the viewing cone.
						'vec4 position4 = vec4(position, 1.0);',
						'vec4 pos_in_cam = viewtransformf * position4;',

						// Intersection of ray and near clipping plane (z = -1 in clip coords)
						'pos_in_cam.z = -pos_in_cam.w;',
						'v_nearpos = viewtransformi * pos_in_cam;',

						// Intersection of ray and far clipping plane (z = +1 in clip coords)
						'pos_in_cam.z = pos_in_cam.w;',
						'v_farpos = viewtransformi * pos_in_cam;',

						// Set varyings and output pos
						'v_position = position;',
						'gl_Position = projectionMatrix * viewMatrix * modelMatrix * position4;',
				'}',
		].join( '\n' ),
	fragmentShader: [
				'precision highp float;',
				'precision mediump sampler3D;',

				'uniform vec3 u_size;',
				'uniform int u_renderstyle;',
				'uniform float u_renderthreshold;',
				'uniform vec2 u_clim;',

				'uniform sampler3D u_data;',
				'uniform sampler2D u_cmdata;',

				'varying vec3 v_position;',
				'varying vec4 v_nearpos;',
				'varying vec4 v_farpos;',

				// The maximum distance through our rendering volume is sqrt(3).
				'const int MAX_STEPS = 887;	// 887 for 512^3, 1774 for 1024^3',
				'const int REFINEMENT_STEPS = 4;',
				'const float relative_step_size = 1.0;',
				'const vec4 ambient_color = vec4(0.2, 0.4, 0.2, 1.0);',
				'const vec4 diffuse_color = vec4(0.8, 0.2, 0.2, 1.0);',
				'const vec4 specular_color = vec4(1.0, 1.0, 1.0, 1.0);',
				'const float shininess = 40.0;',

				'void cast_mip(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray);',
				'void cast_iso(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray);',

				'float sample1(vec3 texcoords);',
				'vec4 apply_colormap(float val);',
				'vec4 add_lighting(float val, vec3 loc, vec3 step, vec3 view_ray);',


				'void main() {',
						// Normalize clipping plane info
						'vec3 farpos = v_farpos.xyz / v_farpos.w;',
						'vec3 nearpos = v_nearpos.xyz / v_nearpos.w;',

						// Calculate unit vector pointing in the view direction through this fragment.
						'vec3 view_ray = normalize(nearpos.xyz - farpos.xyz);',

						// Compute the (negative) distance to the front surface or near clipping plane.
						// v_position is the back face of the cuboid, so the initial distance calculated in the dot
						// product below is the distance from near clip plane to the back of the cuboid
						'float distance = dot(nearpos - v_position, view_ray);',
						'distance = max(distance, min((-0.5 - v_position.x) / view_ray.x,',
																				'(u_size.x - 0.5 - v_position.x) / view_ray.x));',
						'distance = max(distance, min((-0.5 - v_position.y) / view_ray.y,',
																				'(u_size.y - 0.5 - v_position.y) / view_ray.y));',
						'distance = max(distance, min((-0.5 - v_position.z) / view_ray.z,',
																				'(u_size.z - 0.5 - v_position.z) / view_ray.z));',

																				// Now we have the starting position on the front surface
						'vec3 front = v_position + view_ray * distance;',

						// Decide how many steps to take
						'int nsteps = int(-distance / relative_step_size + 0.5);',
						'if ( nsteps < 1 )',
								'discard;',

						// Get starting location and step vector in texture coordinates
						'vec3 step = ((v_position - front) / u_size) / float(nsteps);',
						'vec3 start_loc = front / u_size;',

						// For testing: show the number of steps. This helps to establish
						// whether the rays are correctly oriented
						//'gl_FragColor = vec4(0.0, float(nsteps) / 1.0 / u_size.x, 1.0, 1.0);',
						//'return;',

						'if (u_renderstyle == 0)',
								'cast_mip(start_loc, step, nsteps, view_ray);',
						'else if (u_renderstyle == 1)',
								'cast_iso(start_loc, step, nsteps, view_ray);',

						'if (gl_FragColor.a < 0.05)',
								'discard;',
				'}',


				'float sample1(vec3 texcoords) {',
						'/* Sample float value from a 3D texture. Assumes intensity data. */',
						'return texture(u_data, texcoords.xyz).r;',
				'}',


				'vec4 apply_colormap(float val) {',
						'val = (val - u_clim[0]) / (u_clim[1] - u_clim[0]);',
						'return texture2D(u_cmdata, vec2(val, 0.5));',
				'}',


				'void cast_mip(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray) {',

						'float max_val = -1e6;',
						'int max_i = 100;',
						'vec3 loc = start_loc;',

						// Enter the raycasting loop. In WebGL 1 the loop index cannot be compared with
						// non-constant expression. So we use a hard-coded max, and an additional condition
						// inside the loop.
						'for (int iter=0; iter<MAX_STEPS; iter++) {',
								'if (iter >= nsteps)',
										'break;',
								// Sample from the 3D texture
								'float val = sample1(loc);',
								// Apply MIP operation
								'if (val > max_val) {',
										'max_val = val;',
										'max_i = iter;',
								'}',
								// Advance location deeper into the volume
								'loc += step;',
						'}',

						// Refine location, gives crispier images
						'vec3 iloc = start_loc + step * (float(max_i) - 0.5);',
						'vec3 istep = step / float(REFINEMENT_STEPS);',
						'for (int i=0; i<REFINEMENT_STEPS; i++) {',
								'max_val = max(max_val, sample1(iloc));',
								'iloc += istep;',
						'}',

						// Resolve final color
						'gl_FragColor = apply_colormap(max_val);',
				'}',


				'void cast_iso(vec3 start_loc, vec3 step, int nsteps, vec3 view_ray) {',

						'gl_FragColor = vec4(0.0);	// init transparent',
						'vec4 color3 = vec4(0.0);	// final color',
						'vec3 dstep = 1.5 / u_size;	// step to sample derivative',
						'vec3 loc = start_loc;',

						'float low_threshold = u_renderthreshold - 0.02 * (u_clim[1] - u_clim[0]);',

						// Enter the raycasting loop. In WebGL 1 the loop index cannot be compared with
						// non-constant expression. So we use a hard-coded max, and an additional condition
						// inside the loop.
						'for (int iter=0; iter<MAX_STEPS; iter++) {',
								'if (iter >= nsteps)',
										'break;',

										// Sample from the 3D texture
								'float val = sample1(loc);',

								'if (val > low_threshold) {',
								// Take the last interval in smaller steps
										'vec3 iloc = loc - 0.5 * step;',
										'vec3 istep = step / float(REFINEMENT_STEPS);',
										'for (int i=0; i<REFINEMENT_STEPS; i++) {',
												'val = sample1(iloc);',
												'if (val > u_renderthreshold) {',
														'gl_FragColor = add_lighting(val, iloc, dstep, view_ray);',
														'return;',
												'}',
												'iloc += istep;',
										'}',
								'}',

								// Advance location deeper into the volume
								'loc += step;',
						'}',
				'}',


				'vec4 add_lighting(float val, vec3 loc, vec3 step, vec3 view_ray)',
				'{',
						// Calculate color by incorporating lighting

						// View direction
						'vec3 V = normalize(view_ray);',

						// calculate normal vector from gradient
						'vec3 N;',
						'float val1, val2;',
						'val1 = sample1(loc + vec3(-step[0], 0.0, 0.0));',
						'val2 = sample1(loc + vec3(+step[0], 0.0, 0.0));',
						'N[0] = val1 - val2;',
						'val = max(max(val1, val2), val);',
						'val1 = sample1(loc + vec3(0.0, -step[1], 0.0));',
						'val2 = sample1(loc + vec3(0.0, +step[1], 0.0));',
						'N[1] = val1 - val2;',
						'val = max(max(val1, val2), val);',
						'val1 = sample1(loc + vec3(0.0, 0.0, -step[2]));',
						'val2 = sample1(loc + vec3(0.0, 0.0, +step[2]));',
						'N[2] = val1 - val2;',
						'val = max(max(val1, val2), val);',

						'float gm = length(N); // gradient magnitude',
						'N = normalize(N);',

						// Flip normal so it points towards viewer
						'float Nselect = float(dot(N, V) > 0.0);',
						'N = (2.0 * Nselect - 1.0) * N;	// ==	Nselect * N - (1.0-Nselect)*N;',

						// Init colors
						'vec4 ambient_color = vec4(0.0, 0.0, 0.0, 0.0);',
						'vec4 diffuse_color = vec4(0.0, 0.0, 0.0, 0.0);',
						'vec4 specular_color = vec4(0.0, 0.0, 0.0, 0.0);',

						// note: could allow multiple lights
						'for (int i=0; i<1; i++)',
						'{',
								 // Get light direction (make sure to prevent zero devision)
								'vec3 L = normalize(view_ray);	//lightDirs[i];',
								'float lightEnabled = float( length(L) > 0.0 );',
								'L = normalize(L + (1.0 - lightEnabled));',

								// Calculate lighting properties
								'float lambertTerm = clamp(dot(N, L), 0.0, 1.0);',
								'vec3 H = normalize(L+V); // Halfway vector',
								'float specularTerm = pow(max(dot(H, N), 0.0), shininess);',

								// Calculate mask
								'float mask1 = lightEnabled;',

								// Calculate colors
								'ambient_color +=	mask1 * ambient_color;	// * gl_LightSource[i].ambient;',
								'diffuse_color +=	mask1 * lambertTerm;',
								'specular_color += mask1 * specularTerm * specular_color;',
						'}',

						// Calculate final color by componing different components
						'vec4 final_color;',
						'vec4 color = apply_colormap(val);',
						'final_color = color * (ambient_color + diffuse_color) + specular_color;',
						'final_color.a = color.a;',
						'return final_color;',
				'}',
	].join( '\n' )
});

   
	AFRAME.registerComponent('myloader', {  
	
	    
		init: function () {
		   
		   new NRRDLoader().load( "../../models/nrrd/stent.nrrd", function ( volume ) {
	       var texture = new THREE.DataTexture3D( volume.data, volume.xLength, volume.yLength, volume.zLength  );
		   texture.format = RedFormat;
		   texture.type = FloatType;
		   texture.minFilter = texture.magFilter = LinearFilter;
		   texture.unpackAlignment = 1;
		   texture.needsUpdate = true;
		   
		   // Colormap textures
			cmtextures = {
					viridis: new THREE.TextureLoader().load( 'textures/cm_viridis.png' ),
					gray: new THREE.TextureLoader().load( 'textures/cm_gray.png' )
			};
			
			// Material
			var shader = THREE.ShaderLib[ 'libvolumeRenderShader' ];
			var uniforms = THREE.UniformsUtils.clone( shader.uniforms );
			uniforms[ "u_data" ].value = texture;
			uniforms[ "u_size" ].value.set( volume.xLength, volume.yLength, volume.zLength );
			uniforms[ "u_clim" ].value.set( volconfig.clim1, volconfig.clim2 );
			uniforms[ "u_renderstyle" ].value = volconfig.renderstyle == 'mip' ? 0 : 1; // 0: MIP, 1: ISO
			uniforms[ "u_renderthreshold" ].value = volconfig.isothreshold; // For ISO renderstyle
			uniforms[ "u_cmdata" ].value = cmtextures[ volconfig.colormap ];
			
			material = new THREE.ShaderMaterial( {
					uniforms: uniforms,
					vertexShader: shader.vertexShader,
					fragmentShader: shader.fragmentShader,
					side: BackSide // The volume shader uses the backface as its "reference point"
				} );
            // Mesh
				var geometry = new THREE.BoxBufferGeometry( volume.xLength, volume.yLength, volume.zLength );
				geometry.translate( volume.xLength / 2 - 0.5, volume.yLength / 2 - 0.5, volume.zLength / 2 - 0.5 );
				
				var mesh = new THREE.Mesh( geometry, material );
				this.el.setObject3D('mesh', new THREE.Mesh(geometry, material));
				//render();

		   
	       } );
		
		},
	    
		update: function () {}
	  
	
	});

</script>
  </head>
  <body>
    <a-scene>
     <a-entity myloader position="0 1 -5">
    </a-scene>
  </body>
</html>
